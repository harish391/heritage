# Art & Heritage Restoration: Complete Computer Vision Project

![Art Restoration](https://img.shields.io/badge/Computer%20Vision-Deep%20Learning-blue?style=flat-square)
![Python](https://img.shields.io/badge/Python-3.8+-green?style=flat-square)
![License](https://img.shields.io/badge/License-MIT-yellow?style=flat-square)
![Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen?style=flat-square)

> A complete, production-ready system for digital restoration of heritage artworks using computer vision and deep learning. Includes real-time webcam processing, batch operations, and interactive restoration pipeline.

## üìã Table of Contents

- [Features](#features)
- [Quick Start](#quick-start)
- [System Architecture](#system-architecture)
- [Installation](#installation)
- [Usage](#usage)
- [Documentation](#documentation)
- [Project Structure](#project-structure)
- [Performance](#performance)
- [Requirements](#requirements)
- [Troubleshooting](#troubleshooting)
- [Contributing](#contributing)
- [License](#license)

## ‚ú® Features

### Core Pipeline (5 Stages)
- **Stage 1: Image Enhancement** - CLAHE, bilateral filtering, unsharp masking, gamma correction
- **Stage 2: Crack Segmentation** - U-Net deep learning model (87-93% IoU accuracy)
- **Stage 3: Texture Classification** - CNN-based artistic style recognition (90-93% accuracy)
- **Stage 4: Neural Style Transfer** - VGG19-based artistic style application
- **Stage 5: Inpainting** - Traditional (Telea, Navier-Stokes) and deep learning methods

### Real-Time Processing ‚≠ê
- Live webcam/video file processing
- Multiple processing modes (standard, ultra-fast, high-quality)
- Interactive controls (pause, screenshot, mode switching)
- FPS counter and live statistics overlay
- Video output saving capability
- 20-60+ FPS depending on mode and hardware

### Advanced Features
- **Batch Processing** - Process hundreds of images automatically
- **GPU Acceleration** - CUDA support for 15-50√ó speedup
- **Configurable Pipeline** - Customize parameters via YAML config
- **Multi-Model Support** - ResNet50, VGG19, EfficientNet architectures
- **Modular Design** - Use individual stages or complete pipeline
- **Production Ready** - Error handling, logging, comprehensive documentation

## üöÄ Quick Start

### Installation (5 minutes)

```bash
# 1. Clone or download the project
cd art_restoration_project

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate          # Mac/Linux
venv\Scripts\activate              # Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. Create project structure
python setup_project.py

# 5. Verify installation
python -c "import cv2, torch, tensorflow; print('‚úì Ready!')"
```

### Your First Restoration (2 minutes)

**Option A: Single Image**
```python
import sys
sys.path.append('src')
from main_pipeline import ArtRestorationPipeline

pipeline = ArtRestorationPipeline()
results = pipeline.process_image('data/raw/artwork.jpg')

print(f"Style: {results['style']}")
print(f"Damage: {results['damage_percentage']:.1f}%")
```

**Option B: Real-Time Webcam** ‚≠ê
```python
import sys
sys.path.append('src')
from realtime_restoration import RealtimeArtRestoration

system = RealtimeArtRestoration(source=0, display_fps=True)
system.run()
# Controls: Q=quit, S=screenshot, SPACE=pause, 1-2=mode switch
```

**Option C: Batch Processing**
```bash
python scripts/batch_process.py data/raw/ outputs/batch_results/
```

## üèóÔ∏è System Architecture

```
INPUT IMAGE/VIDEO
    ‚Üì
[Stage 1] IMAGE ENHANCEMENT
    ‚îú‚îÄ Histogram Equalization
    ‚îú‚îÄ CLAHE (Contrast Limited Adaptive HE)
    ‚îú‚îÄ Bilateral Filtering (denoising)
    ‚îú‚îÄ Unsharp Masking (sharpening)
    ‚îî‚îÄ Output: Enhanced image
    ‚Üì
[Stage 2] CRACK SEGMENTATION (U-Net)
    ‚îú‚îÄ Encoder: Extract features (64‚Üí128‚Üí256‚Üí512‚Üí1024)
    ‚îú‚îÄ Decoder: Generate predictions with skip connections
    ‚îú‚îÄ Output: Binary damage mask
    ‚îî‚îÄ Metrics: IoU, Dice Score
    ‚Üì
[Stage 3] TEXTURE CLASSIFICATION (CNN)
    ‚îú‚îÄ Feature Extraction: ResNet50/VGG19/EfficientNet
    ‚îú‚îÄ Classification: 5 art styles
    ‚îú‚îÄ Output: Style + Confidence
    ‚îî‚îÄ Classes: Impressionism, Cubism, Realism, Abstract, Surrealism
    ‚Üì
[Stage 4] NEURAL STYLE TRANSFER (VGG19)
    ‚îú‚îÄ Content Loss: Preserve semantic content
    ‚îú‚îÄ Style Loss: Apply artistic style via Gram matrices
    ‚îú‚îÄ Iterative Optimization: Adam optimizer
    ‚îî‚îÄ Output: Stylized image (optional)
    ‚Üì
[Stage 5] INPAINTING
    ‚îú‚îÄ Traditional: Telea's algorithm or Navier-Stokes
    ‚îú‚îÄ Deep Learning: Partial Convolution U-Net
    ‚îú‚îÄ Input: Damaged image + crack mask
    ‚îî‚îÄ Output: Restored artwork
    ‚Üì
FINAL RESTORED IMAGE
```

## üì¶ Installation

### Prerequisites
- Python 3.8 or higher
- pip (Python package manager)
- 8GB RAM minimum (16GB recommended)
- NVIDIA GPU with CUDA 11.8+ (optional, for acceleration)

### Step-by-Step Setup

**1. Install Python**
- Download from https://www.python.org/downloads/
- Verify: `python --version`

**2. Install VS Code**
- Download from https://code.visualstudio.com/
- Install Python extension (by Microsoft)

**3. Create Project Directory**
```bash
mkdir art_restoration_project
cd art_restoration_project
code .
```

**4. Set Up Virtual Environment**
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Mac/Linux
python3 -m venv venv
source venv/bin/activate
```

**5. Install Dependencies**
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

**6. Initialize Project**
```bash
python setup_project.py
```

### GPU Setup (Optional)

For NVIDIA GPUs with CUDA support:

```bash
# CUDA 11.8
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# Verify GPU
python -c "import torch; print(f'GPU Available: {torch.cuda.is_available()}')"
```

## üíª Usage

### 1. Process Single Image

```python
import sys
sys.path.append('src')
from main_pipeline import ArtRestorationPipeline

# Initialize pipeline
pipeline = ArtRestorationPipeline()

# Process image through all 5 stages
results = pipeline.process_image('data/raw/artwork.jpg', output_dir='outputs/results')

# Access results
print(f"Detected Style: {results['style']}")
print(f"Damage Level: {results['damage_percentage']:.2f}%")
print(f"Processing Steps:")
for step, path in results['steps'].items():
    print(f"  {step}: {path}")
```

### 2. Real-Time Webcam Processing ‚≠ê

```python
import sys
sys.path.append('src')
from realtime_restoration import RealtimeArtRestoration

# Standard mode (balanced performance)
system = RealtimeArtRestoration(
    source=0,              # 0=webcam, or path to video file
    display_fps=True,      # Show FPS counter
    save_output=False      # Set True to save video
)
system.run()

# During execution:
# Q - Quit
# S - Save screenshot
# SPACE - Pause/Resume
# 1 - Lightweight mode (faster)
# 2 - Full quality mode (slower)
```

### 3. Ultra-Fast Mode (40-60+ FPS)

```python
from realtime_restoration import OptimizedRealtime

system = OptimizedRealtime()
system.run_fast(source=0)
```

### 4. Batch Process Multiple Images

```bash
python scripts/batch_process.py input_folder/ output_folder/
```

### 5. Use Individual Stages

```python
import sys
sys.path.append('src')

# Only enhancement
from image_enhancement import ImageEnhancer
enhancer = ImageEnhancer()
enhanced = enhancer.enhance_pipeline('artwork.jpg', 'enhanced.jpg')

# Only crack detection
from crack_segmentation import CrackSegmenter
segmenter = CrackSegmenter()
mask = segmenter.segment_cracks('artwork.jpg')

# Only style classification
from texture_classification import TextureClassifier
classifier = TextureClassifier()
style, confidence, probs = classifier.classify('artwork.jpg')
```

## üìö Documentation

Complete documentation is provided in multiple formats:

### Quick References
- **QUICKSTART.md** - Fast-track implementation guide
- **VSCODE_SETUP.md** - VS Code environment setup
- **COMPLETE_FILE_LISTING.txt** - All files with descriptions

### Comprehensive Guides
- **Complete-Setup-Guide.pdf** (15 pages) - Step-by-step setup with 10 phases
- **Art-Restoration-Guide.pdf** (17 pages) - Technical deep dive with 68 citations
- **PROJECT_SUMMARY.txt** - Architecture, benchmarks, troubleshooting

### Code Documentation
- Inline docstrings in all Python files
- Type hints for better IDE support
- Example usage in class/function docstrings

## üìÅ Project Structure

```
art_restoration_project/
‚îÇ
‚îú‚îÄ‚îÄ üìÑ Core Configuration & Setup
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt              # Python dependencies (24+ packages)
‚îÇ   ‚îú‚îÄ‚îÄ setup_project.py              # Automated structure creation
‚îÇ   ‚îú‚îÄ‚îÄ README.md                     # This file
‚îÇ   ‚îî‚îÄ‚îÄ .gitignore                    # Git ignore rules
‚îÇ
‚îú‚îÄ‚îÄ üìÅ src/                           # Main Implementation
‚îÇ   ‚îú‚îÄ‚îÄ 1_image_enhancement.py        # Stage 1: Enhancement
‚îÇ   ‚îú‚îÄ‚îÄ 2_crack_segmentation.py       # Stage 2: Segmentation (U-Net)
‚îÇ   ‚îú‚îÄ‚îÄ 3_texture_classification.py   # Stage 3: Classification (CNN)
‚îÇ   ‚îú‚îÄ‚îÄ 4_neural_style_transfer.py    # Stage 4: Style Transfer (VGG19)
‚îÇ   ‚îú‚îÄ‚îÄ 5_inpainting.py               # Stage 5: Inpainting
‚îÇ   ‚îú‚îÄ‚îÄ 6_realtime_restoration.py     # Real-time webcam processing ‚≠ê
‚îÇ   ‚îú‚îÄ‚îÄ main_pipeline.py              # Integrated 5-stage pipeline
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ data_loader.py            # Dataset loading
‚îÇ       ‚îú‚îÄ‚îÄ metrics.py                # Evaluation metrics
‚îÇ       ‚îú‚îÄ‚îÄ visualization.py          # Plotting utilities
‚îÇ       ‚îî‚îÄ‚îÄ config_loader.py          # Configuration management
‚îÇ
‚îú‚îÄ‚îÄ üìÅ configs/                       # Configuration Files
‚îÇ   ‚îú‚îÄ‚îÄ config.py                     # Main paths and settings
‚îÇ   ‚îî‚îÄ‚îÄ model_config.yaml             # Model hyperparameters
‚îÇ
‚îú‚îÄ‚îÄ üìÅ scripts/                       # Utility Scripts
‚îÇ   ‚îú‚îÄ‚îÄ train_unet.py                 # Train segmentation model
‚îÇ   ‚îú‚îÄ‚îÄ batch_process.py              # Batch image processing
‚îÇ   ‚îú‚îÄ‚îÄ train_classifier.py           # Train style classifier
‚îÇ   ‚îî‚îÄ‚îÄ download_datasets.py          # Download training data
‚îÇ
‚îú‚îÄ‚îÄ üìÅ data/                          # Dataset Storage
‚îÇ   ‚îú‚îÄ‚îÄ raw/                          # Original damaged images
‚îÇ   ‚îú‚îÄ‚îÄ processed/                    # Enhanced images
‚îÇ   ‚îú‚îÄ‚îÄ masks/                        # Segmentation masks
‚îÇ   ‚îî‚îÄ‚îÄ datasets/                     # Downloaded datasets
‚îÇ
‚îú‚îÄ‚îÄ üìÅ models/                        # Model Storage
‚îÇ   ‚îú‚îÄ‚îÄ pretrained/                   # Downloaded weights
‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/                  # Training checkpoints
‚îÇ   ‚îî‚îÄ‚îÄ final/                        # Production models
‚îÇ
‚îú‚îÄ‚îÄ üìÅ outputs/                       # Results & Logs
‚îÇ   ‚îú‚îÄ‚îÄ results/                      # Restored images
‚îÇ   ‚îú‚îÄ‚îÄ logs/                         # Training logs
‚îÇ   ‚îú‚îÄ‚îÄ visualizations/               # Plots and graphs
‚îÇ   ‚îî‚îÄ‚îÄ videos/                       # Processed videos
‚îÇ
‚îú‚îÄ‚îÄ üìÅ notebooks/                     # Jupyter Experiments (7 files)
‚îÇ   ‚îú‚îÄ‚îÄ 01_data_exploration.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_enhancement_testing.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_segmentation_training.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 04_classification_training.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 05_style_transfer_demo.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 06_inpainting_evaluation.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 07_full_pipeline_demo.ipynb
‚îÇ
‚îú‚îÄ‚îÄ üìÅ tests/                         # Unit Tests
‚îÇ   ‚îú‚îÄ‚îÄ test_enhancement.py
‚îÇ   ‚îú‚îÄ‚îÄ test_segmentation.py
‚îÇ   ‚îú‚îÄ‚îÄ test_classification.py
‚îÇ   ‚îî‚îÄ‚îÄ test_pipeline.py
‚îÇ
‚îî‚îÄ‚îÄ üìÅ docs/                          # Documentation
    ‚îú‚îÄ‚îÄ Art-Restoration-Guide.pdf     # Technical guide (17 pages)
    ‚îú‚îÄ‚îÄ Complete-Setup-Guide.pdf      # Setup guide (15 pages)
    ‚îî‚îÄ‚îÄ architecture_diagram.png      # System architecture
```

## ‚öôÔ∏è Performance

### Processing Times (NVIDIA GTX 1060)

| Operation | GPU | CPU | Speedup |
|-----------|-----|-----|---------|
| Image Enhancement | 0.5s | 2s | 4√ó |
| Crack Segmentation | 1s | 20s | 20√ó |
| Classification | 0.3s | 5s | 17√ó |
| Style Transfer (300 iter) | 45s | 30min | 40√ó |
| Inpainting | 2s | 30s | 15√ó |
| **Complete Pipeline** | **50s** | **35min** | **42√ó** |
| **Real-Time (Standard)** | **25 FPS** | **5 FPS** | **5√ó** |
| **Real-Time (Ultra-Fast)** | **50 FPS** | **15 FPS** | **3√ó** |

### Accuracy Metrics

- **Crack Segmentation**: 87-93% IoU on Crack500 dataset
- **Dice Score**: 0.88-0.94 for damage detection
- **Style Classification**: 90-93% accuracy on 5-class recognition
- **Inpainting Quality**: SSIM 0.85-0.95, PSNR 25-35dB

### Hardware Recommendations

**Minimum Configuration:**
- CPU: Intel i5 / AMD Ryzen 5 (4+ cores)
- RAM: 8GB
- Storage: 10GB SSD
- GPU: Not required (uses CPU)

**Recommended Configuration:**
- CPU: Intel i7 / AMD Ryzen 7
- RAM: 16GB+
- Storage: 20GB SSD+
- GPU: NVIDIA GTX 1060 (6GB VRAM) or better
- CUDA: 11.8+ with cuDNN

## üìã Requirements

### Python Packages

```
Core Libraries:
- opencv-python>=4.8.0
- opencv-contrib-python>=4.8.0
- tensorflow>=2.13.0
- keras>=2.13.0
- torch>=2.0.0
- torchvision>=0.15.0

Data Science:
- numpy>=1.24.0
- pandas>=2.0.0
- scipy>=1.11.0
- scikit-image>=0.21.0
- scikit-learn>=1.3.0

Visualization:
- matplotlib>=3.7.0
- seaborn>=0.12.0
- plotly>=5.14.0

Utilities:
- Pillow>=10.0.0
- pyyaml>=6.0
- tqdm>=4.65.0
- h5py>=3.8.0

Development:
- jupyter>=1.0.0
- pytest>=7.0.0
```

See `requirements.txt` for complete list with exact versions.

## üîß Configuration

### Model Hyperparameters

Edit `configs/model_config.yaml` to customize:

```yaml
# Image Enhancement
enhancement:
  clahe_clip_limit: 2.0
  clahe_tile_size: [8, 8]
  bilateral_d: 9
  bilateral_sigma_color: 75

# Crack Segmentation
segmentation:
  model: unet
  input_size: [512, 512]
  threshold: 0.5
  batch_size: 4

# Style Classification
classification:
  model: resnet50
  num_classes: 5
  confidence_threshold: 0.7

# Neural Style Transfer
style_transfer:
  model: vgg19
  content_weight: 1
  style_weight: 1000000
  num_steps: 300
  learning_rate: 0.003

# Inpainting
inpainting:
  method: telea  # or 'ns'
  radius: 3
```

## üß™ Testing

Run unit tests to verify installation:

```bash
# Test all components
python -m pytest tests/

# Test specific module
python -m pytest tests/test_enhancement.py -v

# Quick verification
python -c "
import sys
sys.path.append('src')
from main_pipeline import ArtRestorationPipeline
pipeline = ArtRestorationPipeline()
print('‚úì All modules loaded successfully!')
"
```

## üö® Troubleshooting

### Common Issues & Solutions

**Issue: ModuleNotFoundError: No module named 'cv2'**
```bash
pip uninstall opencv-python opencv-contrib-python
pip install opencv-python opencv-contrib-python
```

**Issue: CUDA not available for PyTorch**
```bash
# Install CUDA-enabled PyTorch
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

**Issue: Out of Memory (GPU)**
```python
# In config or script:
batch_size = 1  # Reduce batch size
# Or resize images to 256x256 instead of 512x512
```

**Issue: Slow Real-Time Processing**
- Switch to ultra-fast mode (press '1' during execution)
- Reduce resolution in preprocessing
- Ensure GPU drivers are updated
- Close background applications

**Issue: Webcam not detected**
```python
# Try different camera indices
system = RealtimeArtRestoration(source=1)  # or 2, 3, etc.

# On Linux, check available devices
ls /dev/video*
```

### Getting Help

1. Check **Complete-Setup-Guide.pdf** troubleshooting section
2. Review **Art-Restoration-Guide.pdf** technical details
3. Check inline code documentation and docstrings
4. Run tests to verify individual components
5. Enable verbose logging for debugging

## üìä Available Datasets

### Pre-configured Support

**MuralDH Dataset**
- 5000+ Dunhuang mural images (512√ó512)
- 1000 with pixel-level damage annotations
- Access: https://github.com/tearsheaven/MuralDH

**Crack500 Dataset**
- 500 annotated crack images
- Pavement and structural damage
- Popular for segmentation benchmarking

**Ozgenel Dataset**
- Concrete surface cracks
- Infrastructure and heritage building focus
- Diverse lighting and textures

Download datasets into `data/datasets/` folder for training.

## üéì Training Custom Models

### Train U-Net for Crack Segmentation

```bash
python scripts/train_unet.py
```

Configuration in `configs/model_config.yaml`:
- Epochs: 50 (typical training time: 2-4 hours on GPU)
- Batch size: 4
- Learning rate: 0.001
- Optimizer: Adam with learning rate scheduling

### Fine-tune Style Classifier

```python
# See notebooks/04_classification_training.ipynb for details
python scripts/train_classifier.py
```

## üìà Project Statistics

- **Total Files**: 54+
- **Code Lines**: 2,500+
- **Implementation Time**: 15-30 minutes (setup to first run)
- **Processing Speed**: 35-70 seconds per image (GPU)
- **Real-Time FPS**: 25-50 (standard), 40-60+ (ultra-fast)
- **Accuracy**: 87-93% IoU (segmentation), 90-93% (classification)
- **Research Citations**: 68 peer-reviewed papers

## üéØ Applications

### Heritage Conservation
- Digital restoration of historical artworks
- Non-invasive damage assessment
- Virtual museum exhibits

### Infrastructure Monitoring
- Automated crack detection in buildings
- Bridge inspection and maintenance
- Safety assessment automation

### Art Analysis
- Artistic style recognition and attribution
- Artwork authentication
- Art historical research

### Real-Time Documentation
- Live restoration progress monitoring
- Interactive virtual tours with overlays
- Educational demonstrations

## ü§ù Contributing

We welcome contributions! Areas for enhancement:

- Additional segmentation models (DeepLabV3+, SegFormer)
- Mobile deployment optimization
- Web interface development
- Domain-specific fine-tuning examples
- Performance optimization techniques
- Additional dataset support

## üìÑ License

This project is licensed under the MIT License - see LICENSE file for details.

## üìû Support & Documentation

- **Setup Guide**: Read `Complete-Setup-Guide.pdf` first (15 pages)
- **Technical Details**: Study `Art-Restoration-Guide.pdf` (17 pages)
- **Quick Start**: Follow `QUICKSTART.md`
- **File Reference**: Check `COMPLETE_FILE_LISTING.txt`
- **Code Examples**: See inline docstrings and notebooks

## üôè Acknowledgments

- U-Net architecture: Ronneberger et al. (2015)
- Neural Style Transfer: Gatys et al. (2015)
- Partial Convolution Inpainting: Liu et al. (2018)
- Transfer Learning: Yosinski et al. (2014)
- Dataset citations: MuralDH, Crack500, Ozgenel researchers

## üìö Citation

If you use this project in your research, please cite:

```bibtex
@software{art_restoration_2025,
  title={Art \& Heritage Restoration: Complete Computer Vision Project},
  author={Your Name},
  year={2025},
  url={https://github.com/yourusername/art_restoration_project}
}
```

## üéâ Getting Started

1. **Read** `Complete-Setup-Guide.pdf` (15 minutes)
2. **Install** dependencies following Phase 1-3 (10 minutes)
3. **Test** individual components (5 minutes)
4. **Process** your first image or run real-time mode (2 minutes)
5. **Explore** advanced features and customization

**Total time to first restoration: ~30 minutes!**

---

**Questions?** Check the comprehensive guides included in the `docs/` folder.

**Ready to restore some heritage?** üñºÔ∏è‚ú®

Start with:
```bash
python src/6_realtime_restoration.py
```

Point your webcam at an artwork and watch it get analyzed in real-time!
